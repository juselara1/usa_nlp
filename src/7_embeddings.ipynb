{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmGmRLfHpRwj",
        "outputId": "78dbd83b-ce1f-435c-d646-a2606da02af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "kX9LTinvDE4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import nltk\n",
        "import json\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.fasttext import FastText, load_facebook_model\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwd1rKHRqGor",
        "outputId": "40e598a0-0e53-47bb-a912-e6f8bc5bc979"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = requests.get(\"https://es.wikipedia.org/wiki/Gabriel_Garc%C3%ADa_M%C3%A1rquez\")\n",
        "text = BeautifulSoup(r.text).find(id=\"bodyContent\").get_text()\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQEeSwI0qS1b",
        "outputId": "5c196f80-bde9-446c-d187-10a834a6bc1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "De Wikipedia, la enciclopedia libre\n",
            "\n",
            "\n",
            " Para otros usos de este término, véase Gabriel García Márquez (desambiguación).\n",
            "Gabriel García Márquez\n",
            "Información personalNombre de nacimiento\n",
            "Gabriel José de la Concordia García MárquezApodo\n",
            "Gabo y Gabito Nacimiento\n",
            "6 de marzo de 1927Aracataca, ColombiaFallecimiento\n",
            "17 de abril de 2014(87 años)Ciudad de México, MéxicoCausa de muerte\n",
            "Linfoma y neumonía Nacionalidad\n",
            "ColombianaReligión\n",
            "Ninguna[1]​Lengua materna\n",
            "españolFamiliaPadres\n",
            "Gabriel Eligio García\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = sent_tokenize(text, language=\"spanish\")\n",
        "token_corpus = list(\n",
        "    map(lambda text: word_tokenize(text, language=\"spanish\"), corpus)\n",
        "    )"
      ],
      "metadata": {
        "id": "FNny3q-Hq_KP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(\n",
        "    sentences=token_corpus,\n",
        "    vector_size=30, window=5,\n",
        "    epochs=100\n",
        ")"
      ],
      "metadata": {
        "id": "7jWkS4r3rGkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"Gabriel\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cAw1GDNrUry",
        "outputId": "78481c36-09fc-4fb7-a6f2-3f02efdfc363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.1653433 , -0.2031339 ,  1.0991182 ,  0.41099328,  0.8421217 ,\n",
              "        2.0153196 ,  0.3967291 ,  1.7735747 , -1.1519482 , -0.5840211 ,\n",
              "        0.29051694, -0.7709609 , -0.04464471,  0.807368  ,  0.07149083,\n",
              "        1.7476692 , -0.39258817,  1.5398968 ,  0.28327766,  1.028764  ,\n",
              "        0.7390918 , -1.1277572 , -0.73093534, -1.2742177 , -2.1998098 ,\n",
              "        0.32261294,  1.6925601 ,  0.14601694, -0.1746849 , -1.9351139 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"Gabo\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVQ_jrt4tRSm",
        "outputId": "62c86837-96e3-4cac-da40-c9835f7b4b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.41617996, -0.47393602, -0.90368354,  0.43878633, -0.7694414 ,\n",
              "       -0.2905818 , -0.5480838 ,  0.5951945 , -1.6479701 ,  0.19318701,\n",
              "        0.04539264, -1.3560209 ,  0.594793  , -0.63729763,  0.95032066,\n",
              "        0.987899  , -0.20665541, -0.54823625, -0.9279509 , -0.38103274,\n",
              "       -1.770348  , -0.17512257,  0.39969203,  1.2930186 , -0.8252292 ,\n",
              "        2.1104505 ,  0.08653994, -0.2335215 ,  1.2104933 , -1.3020506 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=\"Colombia\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4DoOxgRtYH6",
        "outputId": "662b7975-2377-4b5d-9f48-46afa73fad35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Nacional', 0.8236978650093079),\n",
              " ('Universidad', 0.772428035736084),\n",
              " ('Cultura', 0.6060214638710022),\n",
              " ('México', 0.5848041772842407),\n",
              " ('Bogotá', 0.5642155408859253),\n",
              " ('marzo', 0.553557813167572),\n",
              " ('ciudad', 0.5334460735321045),\n",
              " ('donde', 0.5021669268608093),\n",
              " ('Indias', 0.4985002279281616),\n",
              " ('casa', 0.49289050698280334)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FastText"
      ],
      "metadata": {
        "id": "NlVH_Nf7DKAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastText(\n",
        "    sentences=token_corpus,\n",
        "    vector_size=100,\n",
        "    window=11,\n",
        "    epochs=100,\n",
        "    workers=-1, # todos procesos posibles\n",
        "    min_n=2,\n",
        "    max_n=4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_PNhH10EdXV",
        "outputId": "3a544b51-64c4-4c82-ec40-e40cddda136a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 5: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 5: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 6: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 6: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 7: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 7: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 8: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 8: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 9: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 9: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 10: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 10: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 11: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 11: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 12: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 12: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 13: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 13: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 14: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 14: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 15: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 15: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 16: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 16: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 17: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 17: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 18: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 18: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 19: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 19: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 20: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 20: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 21: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 21: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 22: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 22: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 23: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 23: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 24: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 24: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 25: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 25: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 26: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 26: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 27: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 27: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 28: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 28: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 29: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 29: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 30: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 30: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 31: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 31: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 32: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 32: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 33: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 33: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 34: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 34: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 35: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 35: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 36: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 36: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 37: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 37: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 38: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 38: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 39: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 39: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 40: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 40: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 41: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 41: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 42: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 42: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 43: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 43: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 44: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 44: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 45: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 45: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 46: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 46: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 47: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 47: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 48: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 48: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 49: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 49: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 50: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 50: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 51: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 51: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 52: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 52: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 53: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 53: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 54: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 54: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 55: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 55: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 56: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 56: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 57: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 57: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 58: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 58: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 59: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 59: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 60: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 60: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 61: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 61: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 62: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 62: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 63: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 63: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 64: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 64: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 65: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 65: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 66: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 66: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 67: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 67: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 68: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 68: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 69: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 69: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 70: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 70: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 71: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 71: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 72: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 72: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 73: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 73: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 74: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 74: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 75: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 75: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 76: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 76: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 77: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 77: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 78: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 78: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 79: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 79: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 80: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 80: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 81: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 81: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 82: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 82: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 83: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 83: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 84: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 84: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 85: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 85: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 86: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 86: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 87: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 87: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 88: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 88: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 89: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 89: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 90: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 90: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 91: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 91: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 92: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 92: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 93: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 93: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 94: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 94: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 95: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 95: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 96: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 96: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 97: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 97: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 98: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 98: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 99: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 99: supplied raw word count (0) did not equal expected count (15876)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"Gabriel\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgojo7pYE7OR",
        "outputId": "ae9b3ccc-9a45-4696-d44e-67adfc063df1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.2825720e-03,  3.3634133e-03,  6.9794187e-04,  1.5674806e-03,\n",
              "       -1.8455819e-03, -7.7922811e-04,  1.4604117e-03,  6.7216024e-04,\n",
              "       -3.2834648e-04,  1.3252437e-03,  1.3645310e-03,  2.2551209e-04,\n",
              "       -2.0865661e-03, -1.1761439e-03, -6.9332094e-04,  1.0694325e-03,\n",
              "       -9.9917990e-04, -1.5752130e-03, -6.0709554e-05, -2.6868947e-04,\n",
              "       -8.1602036e-04, -6.5683060e-05, -5.8482570e-04, -2.8080812e-03,\n",
              "       -2.0461362e-03,  7.1144220e-04,  2.0017350e-04,  1.3917329e-04,\n",
              "        2.3607484e-03, -9.1688125e-04,  8.3640945e-04,  2.0739395e-04,\n",
              "       -1.7197136e-03, -8.4530376e-04,  1.1155282e-03,  1.7748318e-03,\n",
              "        2.7796970e-04,  3.7653549e-04,  1.3517077e-03, -1.2656861e-03,\n",
              "       -1.3334055e-03,  5.2007905e-04, -7.0175400e-04, -1.1713171e-03,\n",
              "       -1.8079599e-03, -3.6976123e-04,  1.8028122e-04,  1.2497599e-03,\n",
              "        1.1059097e-03,  1.9408116e-04, -1.8344466e-04, -3.3249452e-03,\n",
              "       -2.0254678e-05,  5.4246548e-04,  5.6656724e-04,  3.4641250e-04,\n",
              "        2.4846853e-03,  2.1463673e-04, -1.4009356e-03,  6.0427428e-04,\n",
              "       -8.6332526e-04,  8.4314751e-04,  8.5168704e-04,  2.2294029e-04,\n",
              "       -8.4195920e-04,  2.7048935e-03,  1.4924700e-03, -1.1644961e-03,\n",
              "       -4.6933803e-04, -2.0157921e-03,  2.2724355e-03,  1.9288986e-03,\n",
              "       -9.5048454e-05, -2.0923270e-04,  2.2902375e-03, -2.5668289e-04,\n",
              "       -9.9040486e-04, -1.2563275e-03,  1.7395567e-03,  8.2974223e-04,\n",
              "        2.8697692e-03,  8.4419305e-05, -4.1315925e-05,  7.2052650e-04,\n",
              "        1.2808873e-03,  4.0360319e-04, -1.7627549e-03, -6.5687823e-04,\n",
              "       -3.7173173e-04,  5.0858833e-04,  1.8332750e-04, -2.5052442e-03,\n",
              "        5.4839969e-04,  1.2052752e-03, -4.4838144e-04, -9.0900302e-04,\n",
              "       -2.7157866e-05, -1.1262902e-03,  1.4681219e-03,  5.3561386e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"Gabo\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1v5BJ4XE-gQ",
        "outputId": "5bd55597-6143-490c-9879-cb307aa9adb4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.11654575e-03, -1.13629608e-03, -1.30498770e-03, -5.66056347e-04,\n",
              "       -2.35087937e-03,  2.22872104e-03, -1.10445474e-03, -6.66834094e-05,\n",
              "       -8.27730692e-04,  3.21107614e-03, -5.13166189e-04, -1.39916083e-03,\n",
              "       -1.42341212e-03, -7.66406825e-04, -3.74628487e-03,  2.20385351e-04,\n",
              "       -6.94996037e-04, -2.09968211e-03,  1.58831046e-03, -1.92340720e-03,\n",
              "        4.05378640e-04,  2.47975159e-03, -1.70525018e-04, -1.36457407e-03,\n",
              "       -3.18366638e-03, -5.36429638e-04,  4.74777567e-04,  3.83964879e-03,\n",
              "       -7.85337761e-04,  1.22038962e-03, -9.32179741e-04,  1.27546105e-03,\n",
              "        1.91112736e-03, -2.12618057e-03, -4.54801630e-05, -1.66179927e-03,\n",
              "        2.44554156e-03, -5.41665533e-04, -2.94796046e-04, -4.28335415e-03,\n",
              "        1.56287424e-04, -1.78675179e-03,  1.02628524e-04, -7.52469932e-04,\n",
              "       -3.16209951e-03,  2.07504793e-03, -2.38113268e-03, -8.00468726e-04,\n",
              "        4.60182491e-04,  2.82670726e-06, -3.69918453e-05, -6.46120534e-05,\n",
              "       -1.22537196e-03, -1.72309403e-03, -2.84473808e-03,  2.19852733e-03,\n",
              "        4.47054673e-03, -4.94544441e-03, -2.93301826e-04, -2.12053861e-03,\n",
              "        7.02253950e-04,  8.12280923e-04,  1.89852683e-04,  4.62131546e-04,\n",
              "       -2.77381879e-03,  1.57176889e-03,  2.92202094e-05,  8.44078430e-04,\n",
              "        1.46822436e-04,  5.94275152e-05,  3.67375114e-03,  9.94613860e-04,\n",
              "        2.04998953e-03,  2.01908685e-03,  1.40003802e-03,  2.04081251e-03,\n",
              "       -7.01620011e-04, -2.66051409e-03,  8.86575668e-04,  9.67166998e-05,\n",
              "        1.65888062e-03,  2.32430524e-03,  1.48729666e-03,  3.62738181e-04,\n",
              "       -7.10091903e-04, -2.72139255e-03, -7.84228265e-04, -1.80221605e-03,\n",
              "       -7.78062851e-04,  1.53378281e-03, -2.17370980e-04, -9.70039458e-04,\n",
              "        1.08850631e-03, -6.94962102e-04, -3.89984198e-04,  1.74836302e-03,\n",
              "        2.09535891e-03,  1.61756261e-03,  1.08419813e-03, -7.29180872e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"Gabito\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUAPnSpSFAn7",
        "outputId": "3d330d9c-dba2-4240-d63b-672df95e062e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.4365071e-04,  1.4046913e-03,  1.8026499e-03,  1.3696642e-03,\n",
              "       -1.8107072e-03, -1.7881002e-03,  2.0178563e-03,  1.1344660e-03,\n",
              "       -8.9751607e-05,  3.8275057e-03, -2.1281918e-03, -6.4916001e-04,\n",
              "       -4.2032503e-04, -1.9483923e-03, -1.3845712e-03, -1.3734814e-03,\n",
              "       -3.3926826e-03, -1.7935383e-03,  6.2944606e-04,  3.8575195e-04,\n",
              "        9.8380551e-04,  2.6101815e-03,  1.7573281e-04,  4.6038008e-04,\n",
              "       -1.6848412e-03,  7.5011037e-04, -3.3932331e-04,  1.2879818e-03,\n",
              "       -7.4492040e-05,  1.7943329e-03, -1.6725255e-03, -1.2509915e-04,\n",
              "       -1.5468292e-03, -1.3429711e-03, -1.9465291e-04, -6.8871159e-04,\n",
              "        8.8892813e-04,  7.7144499e-04,  6.3330028e-04, -3.3756595e-03,\n",
              "       -5.7844579e-04, -2.6810914e-04, -8.2018785e-04, -1.3080669e-03,\n",
              "       -2.3514985e-03,  2.6293625e-03,  2.8168265e-04,  7.0443226e-04,\n",
              "       -7.3403073e-04,  1.0541031e-03,  1.0908983e-03, -3.4708797e-04,\n",
              "       -7.0906091e-05, -4.2068175e-05, -4.5946758e-04,  1.5536116e-03,\n",
              "        2.9940649e-03, -2.6230721e-03,  8.2223344e-04, -1.1732779e-03,\n",
              "       -1.9267856e-03, -7.2688237e-04, -1.1840011e-03, -8.6478982e-04,\n",
              "       -4.8632867e-04,  1.3685781e-03, -1.1912510e-03,  4.4813799e-04,\n",
              "       -2.9880456e-03, -4.7864311e-04,  1.6577715e-03,  1.4965921e-03,\n",
              "        1.1348640e-04, -7.8368525e-04, -1.8215643e-03,  8.6221215e-04,\n",
              "       -1.9265421e-03,  1.3919902e-04,  4.3780725e-05,  7.6042052e-04,\n",
              "        4.8207544e-04, -3.4512673e-04, -1.2480718e-04,  1.1940843e-03,\n",
              "        2.3603269e-03, -2.1700757e-03, -6.7027932e-04, -2.4747299e-03,\n",
              "        1.1622305e-03, -1.3598858e-03,  4.9644441e-04, -1.5052267e-03,\n",
              "       -7.6132310e-05, -1.4073474e-03,  4.9166098e-05,  1.0290272e-03,\n",
              "        4.2200217e-04,  1.2354949e-03, -1.4186376e-03, -1.1852462e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"casa\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVqg57l5FCzG",
        "outputId": "a1497d7e-c24a-497e-e782-f4df24da251d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.3613232e-04,  9.1708236e-04, -1.1383918e-03, -2.3771099e-04,\n",
              "       -1.0713188e-03, -2.3045531e-03, -2.2912745e-03, -2.1096000e-03,\n",
              "       -5.3885503e-04, -2.8555340e-03, -4.7643651e-05, -1.0279008e-03,\n",
              "       -1.3159866e-03, -1.6093695e-03, -4.1233432e-03,  2.1830688e-03,\n",
              "        4.5654506e-05, -2.6384937e-03, -9.2364143e-04, -6.7448273e-04,\n",
              "       -1.3252546e-03,  2.7308809e-03, -3.3182029e-03, -2.1652561e-03,\n",
              "       -2.0353009e-03, -6.7350228e-04, -3.2588942e-03,  1.8949398e-04,\n",
              "        1.4745685e-03, -1.7171043e-04,  1.7201298e-04,  3.7009997e-04,\n",
              "        1.2776142e-03, -5.5737619e-04,  1.0272939e-03,  1.0367999e-03,\n",
              "        1.2332047e-03,  4.4015932e-04, -1.9911272e-03,  1.5545363e-03,\n",
              "        7.7735854e-04,  1.8027113e-04, -2.2124024e-03,  5.4656173e-04,\n",
              "       -2.1342968e-03, -7.6760008e-04,  6.0149148e-04, -2.9420741e-03,\n",
              "        1.9333103e-03, -1.4885875e-03, -1.2251276e-04,  3.6438258e-04,\n",
              "       -7.1023486e-04, -5.1044137e-04,  3.9790678e-04, -3.1172873e-05,\n",
              "        4.2119937e-04,  3.1573130e-03, -2.2905173e-03, -1.1816272e-03,\n",
              "        1.3148921e-03, -2.8560136e-03,  6.9818401e-04, -1.1182764e-03,\n",
              "       -6.6739827e-04, -2.0132519e-03,  1.6683490e-03,  3.4661248e-04,\n",
              "        4.7666163e-04,  3.5770577e-03, -3.7837779e-04,  1.8679039e-04,\n",
              "       -1.5674903e-03, -1.4579593e-03,  2.9346454e-03,  2.6644962e-03,\n",
              "       -7.9544540e-04, -1.5660473e-03,  5.3600181e-04,  3.2493530e-03,\n",
              "       -1.2947072e-03,  1.1527754e-03,  6.0274766e-04, -1.7869541e-03,\n",
              "        3.3920149e-03, -1.2428600e-04, -1.3394130e-03, -2.3787469e-03,\n",
              "        7.6792421e-05, -1.8327888e-03, -3.1590089e-04, -4.1161510e-03,\n",
              "        5.6736683e-04,  3.5648521e-03, -5.7600986e-04,  2.6673355e-04,\n",
              "       -1.0869886e-03, -2.7533104e-03,  2.6200733e-03,  4.7803621e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"hogar\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq-xtAaiFEir",
        "outputId": "3cdac83f-fd19-482a-969b-c66869afb27a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.9275337e-04,  1.0952094e-03, -7.5969780e-05,  1.9847511e-03,\n",
              "       -2.1774897e-03, -3.6627927e-03, -5.5409141e-04,  1.9767922e-03,\n",
              "        6.7758816e-04, -1.0897525e-03, -8.9357613e-04,  1.2734298e-03,\n",
              "       -1.2207428e-03, -2.0896448e-03, -3.0743184e-03, -2.1915830e-04,\n",
              "        2.9832907e-03, -5.2807637e-04,  2.2003977e-03, -1.2310356e-03,\n",
              "        8.4489817e-05, -2.2069397e-03, -1.5191346e-03, -1.3194049e-03,\n",
              "        3.5524354e-03,  2.2568668e-03, -9.6709270e-04, -1.5058111e-03,\n",
              "        1.2869606e-03, -5.6051568e-04,  1.6007827e-03,  2.2007881e-04,\n",
              "        2.2702562e-03, -9.8188280e-04, -5.9820001e-04, -6.2580989e-04,\n",
              "        1.6972470e-03,  8.6130778e-04, -3.1278592e-05,  5.1020936e-04,\n",
              "        8.8554842e-04, -2.6450772e-04, -2.4010600e-03, -2.1597908e-03,\n",
              "       -1.7921533e-04,  5.9434329e-04, -1.0892855e-03,  5.5598735e-04,\n",
              "       -4.6033604e-04,  2.4641142e-03, -4.6593434e-04, -6.7812053e-04,\n",
              "        1.2827322e-03, -1.1461800e-03, -4.2464040e-04,  1.9697179e-03,\n",
              "       -6.6325604e-04,  2.6603879e-03,  2.8210604e-03,  2.0278671e-03,\n",
              "        3.1801821e-03, -2.5298535e-03, -7.1216351e-04, -1.8667470e-03,\n",
              "       -2.3271330e-03,  1.0349560e-03,  1.1494820e-03,  2.0602730e-03,\n",
              "       -1.1471008e-03,  1.2491070e-03,  2.5724532e-04,  1.6744112e-04,\n",
              "        6.6866074e-04, -2.5606044e-03,  6.6264655e-04,  1.5562661e-04,\n",
              "        1.1480387e-03, -2.6294077e-03, -7.1465003e-04, -3.2972747e-03,\n",
              "        1.0677855e-03, -1.7909914e-04,  2.5317487e-03, -2.0322537e-03,\n",
              "        8.4469495e-05, -1.3011487e-03,  5.1436684e-04,  2.6082250e-04,\n",
              "       -8.1347738e-04,  1.2008512e-03,  9.1130548e-04, -7.2093506e-04,\n",
              "       -1.5526210e-03,  9.3732984e-04, -1.0072886e-03, -2.5858348e-03,\n",
              "        1.9790202e-03,  2.1847384e-03, -9.9604635e-04,  1.4373701e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[[\"este\", \"es\", \"un\", \"ejemplo\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-gOAYdwFVS8",
        "outputId": "a0db9f3e-897b-4a63-f328-42775c4e3ebd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.03238504e-03,  2.51437828e-04,  2.53895065e-03,\n",
              "        -1.28902134e-03,  2.08124286e-03,  3.87267512e-03,\n",
              "        -4.80800227e-04,  2.19627121e-03, -6.10825722e-04,\n",
              "        -2.34538154e-03,  3.13151837e-03, -4.25834674e-03,\n",
              "        -2.71523534e-03,  2.61084945e-03, -1.62683928e-03,\n",
              "         1.42182386e-03,  2.32911902e-03, -6.35979173e-04,\n",
              "        -9.48637840e-04, -2.63438257e-03,  8.02029273e-04,\n",
              "         1.69351639e-03, -1.42094097e-03, -1.46485792e-04,\n",
              "        -1.83451833e-04,  3.62736150e-03,  7.26207392e-04,\n",
              "         5.27288823e-04, -2.09289999e-03,  3.96457326e-04,\n",
              "        -3.85583320e-04, -1.73845189e-03,  9.03095934e-04,\n",
              "         1.00337749e-03,  2.31013913e-03, -3.93811169e-05,\n",
              "        -2.44619267e-04, -3.71146016e-05,  1.89452420e-03,\n",
              "         1.40302524e-03, -3.29648428e-05, -3.04767722e-03,\n",
              "         1.54071779e-03,  1.57865707e-03, -6.38026468e-05,\n",
              "        -1.58809265e-03,  2.70933285e-03, -9.89870750e-04,\n",
              "        -2.66734301e-03, -4.51040891e-04, -2.30196118e-03,\n",
              "         1.49935007e-03,  1.34407158e-03, -6.79016637e-04,\n",
              "         2.41111428e-03,  3.18888851e-05,  1.60632399e-03,\n",
              "         5.62126050e-04,  3.94416647e-03,  7.95655942e-04,\n",
              "         2.68989429e-03, -3.76570068e-04,  1.44515722e-03,\n",
              "         2.53553712e-03,  2.10950081e-03,  1.65048009e-03,\n",
              "         7.62804644e-04, -1.32686214e-03,  1.65064773e-03,\n",
              "        -1.33664915e-04,  1.30645453e-03,  3.02475365e-03,\n",
              "         1.65830180e-03, -8.40116700e-04, -1.85458374e-03,\n",
              "         2.01448845e-03,  2.56425265e-04, -1.68511760e-03,\n",
              "         6.55205047e-04,  2.30348622e-03, -4.97493529e-05,\n",
              "         1.89931388e-03,  2.72338069e-03, -1.87360041e-04,\n",
              "         3.01031163e-03, -1.36391900e-03, -1.84762175e-03,\n",
              "         1.40503992e-03, -4.15890769e-04,  1.21859586e-04,\n",
              "         3.37566104e-04,  2.93500547e-04,  7.57272239e-04,\n",
              "         1.25073851e-03,  1.93981687e-03,  3.90978166e-05,\n",
              "        -8.41207919e-04, -1.38476572e-03, -1.65822217e-03,\n",
              "        -2.32321536e-03],\n",
              "       [-1.01147848e-03, -1.93180924e-03,  1.73574395e-03,\n",
              "        -1.93232601e-03,  1.15896948e-03,  3.89319984e-03,\n",
              "         1.95896043e-03,  1.52902189e-03, -3.57470429e-03,\n",
              "         2.24052975e-03,  8.86984169e-04, -3.25776869e-03,\n",
              "        -2.47263873e-04, -1.54670083e-03,  2.78262375e-03,\n",
              "         3.15603946e-04,  4.09149705e-03,  2.32457370e-03,\n",
              "         3.59859550e-03,  1.36216299e-03, -1.50781020e-03,\n",
              "         4.41774901e-04, -3.24958982e-03, -2.93835677e-04,\n",
              "        -4.37037554e-03,  2.40553031e-03, -2.31995224e-03,\n",
              "        -5.44854731e-04, -1.56162737e-03, -8.26270145e-04,\n",
              "        -1.82510260e-03,  9.18875041e-04, -5.03511168e-04,\n",
              "         2.20318651e-03,  7.92440493e-04,  6.37999910e-04,\n",
              "         5.65769291e-03,  2.73323618e-03, -4.14724927e-03,\n",
              "        -1.12475478e-03, -2.09586439e-03, -2.77883885e-03,\n",
              "         5.05298981e-03,  3.92499007e-03, -3.91181279e-03,\n",
              "        -9.01407475e-05,  4.81347524e-04,  3.60303209e-03,\n",
              "         3.06395045e-03, -1.35073916e-03, -7.95217871e-04,\n",
              "         3.99487559e-03,  7.04196689e-04, -5.40374487e-04,\n",
              "         3.61907482e-03, -2.02093855e-03,  4.37847484e-04,\n",
              "        -1.82665500e-03,  8.39813519e-03, -1.13687932e-03,\n",
              "         5.14756612e-05, -4.99524758e-04, -8.18668050e-04,\n",
              "         2.07650964e-03,  1.34416833e-03,  2.87373783e-03,\n",
              "         2.59049237e-03,  1.97770866e-03,  1.70717575e-03,\n",
              "         1.40729209e-03,  1.50311121e-03, -1.10168441e-03,\n",
              "         1.78236212e-03, -1.33333460e-03, -1.63828465e-03,\n",
              "         2.23710574e-03, -8.33805127e-04, -1.25504693e-03,\n",
              "         2.74846493e-03,  2.24847579e-03, -2.18547508e-03,\n",
              "         9.71529924e-04,  2.54616607e-04, -2.20842689e-04,\n",
              "         1.17672076e-04, -2.52134586e-03, -3.12802894e-03,\n",
              "         5.16264350e-04, -3.25574598e-04,  6.63510233e-04,\n",
              "        -1.91891636e-03,  7.40095682e-04, -7.79603506e-05,\n",
              "        -2.45866599e-04,  2.32524169e-03,  3.16254213e-03,\n",
              "         2.10156897e-03,  9.87575389e-04, -3.21812520e-04,\n",
              "        -1.40106224e-03],\n",
              "       [ 1.02223142e-03, -2.55511282e-03, -1.14756648e-03,\n",
              "         3.94097343e-03, -4.46160819e-04,  9.02899483e-04,\n",
              "        -4.31389082e-03, -1.32789661e-03, -4.12512105e-03,\n",
              "         1.85786502e-03,  6.36239420e-04, -1.13950511e-04,\n",
              "         2.50295969e-03, -7.90991704e-04,  8.85570480e-04,\n",
              "        -3.09469551e-03,  8.67560593e-05, -3.38558969e-03,\n",
              "         2.04921025e-03,  3.11587268e-04, -6.15738682e-04,\n",
              "        -1.97701599e-03, -4.85504791e-03, -7.52794658e-05,\n",
              "         5.40693814e-04,  2.16880013e-04,  1.98608893e-03,\n",
              "        -4.00650722e-04,  7.26625323e-04,  8.20800371e-04,\n",
              "        -2.03972426e-03, -2.65314127e-03, -5.34587125e-05,\n",
              "        -3.88580636e-04,  5.65232849e-03,  1.28327010e-04,\n",
              "        -6.80398312e-04, -4.73961700e-03,  1.45264284e-03,\n",
              "        -8.75108235e-04,  8.94772063e-04, -3.37241872e-05,\n",
              "         3.00924905e-04,  8.43898393e-04, -3.57157690e-03,\n",
              "        -5.68045478e-04, -4.99173673e-03, -2.58398079e-03,\n",
              "        -8.54476995e-04, -9.34292213e-04, -7.82318966e-05,\n",
              "         2.23007728e-03, -2.99142720e-03,  2.50368845e-04,\n",
              "         5.15209790e-03, -4.50558495e-03,  2.44444795e-03,\n",
              "         8.50725919e-05, -3.72371939e-03,  1.05537043e-03,\n",
              "        -2.29622773e-03,  3.20131099e-03, -2.32511316e-03,\n",
              "         6.91691821e-04,  2.37554917e-03, -9.09679293e-05,\n",
              "        -6.81906182e-04,  2.00930540e-03, -1.03588402e-03,\n",
              "        -3.73468094e-04,  2.33102101e-03, -3.99888493e-04,\n",
              "        -1.60745182e-03, -2.13705632e-03, -1.04666699e-03,\n",
              "        -1.97071378e-04, -3.49232228e-03,  1.11664354e-03,\n",
              "         8.97423830e-04,  2.37086578e-03, -2.92786444e-03,\n",
              "        -3.95773770e-03,  2.15455680e-03,  2.49880576e-03,\n",
              "         1.18468411e-03,  1.47042167e-03,  1.17654935e-03,\n",
              "         9.44702246e-04,  4.72335560e-05,  4.48507577e-04,\n",
              "         9.58659279e-04, -1.47152133e-03, -1.66330094e-04,\n",
              "        -1.16491679e-03,  4.03084938e-04, -4.86814737e-04,\n",
              "         1.17948360e-03,  8.92298936e-04,  2.56803207e-04,\n",
              "         1.39727339e-03],\n",
              "       [-1.84556015e-03,  1.17952167e-03, -1.42755103e-03,\n",
              "         4.22141980e-04, -2.07319288e-04, -4.50488937e-04,\n",
              "        -3.50649098e-05,  1.72701897e-03, -2.29453086e-03,\n",
              "         1.16566161e-03, -9.14359058e-04, -1.47861242e-03,\n",
              "        -1.65708561e-03, -2.27052369e-03, -1.65909389e-03,\n",
              "         1.35080656e-03, -9.60809761e-04,  5.78953361e-04,\n",
              "        -2.36467677e-04,  3.20292427e-03,  1.05257996e-03,\n",
              "         1.41107466e-03, -2.56338360e-04, -1.40554749e-03,\n",
              "        -9.80302226e-04,  2.94493069e-03, -1.14602124e-04,\n",
              "        -3.56517150e-04, -1.41671975e-03, -1.35747425e-03,\n",
              "        -3.99980403e-04,  7.02314253e-04, -1.33879890e-03,\n",
              "        -3.78405501e-04,  8.37015614e-05, -2.42172227e-05,\n",
              "        -5.83809917e-04, -7.43545825e-04,  9.19318409e-04,\n",
              "        -3.99951998e-04,  4.41537326e-04, -6.71003945e-04,\n",
              "        -1.08010147e-03,  2.39360472e-03,  2.71706260e-03,\n",
              "        -3.79112113e-04, -1.10384962e-03,  1.62960670e-03,\n",
              "        -1.34241267e-03,  6.48667978e-04,  1.56279420e-03,\n",
              "         4.32855195e-05, -7.39939336e-04,  6.45536929e-04,\n",
              "        -1.40821759e-03,  1.36487361e-03,  1.40801119e-03,\n",
              "         3.92597605e-04, -8.80044885e-04,  4.19060583e-04,\n",
              "        -1.27767125e-04,  7.14088557e-04, -5.17486886e-04,\n",
              "        -1.12994407e-04, -2.55991309e-03,  8.04030744e-04,\n",
              "        -1.42254343e-03,  4.01059631e-04,  6.74726965e-04,\n",
              "        -2.43367092e-03,  3.03912617e-04, -4.22283978e-04,\n",
              "        -1.41134951e-03,  6.19558385e-04,  1.28264388e-03,\n",
              "        -4.62619681e-03, -8.90024356e-04,  1.62392011e-04,\n",
              "        -1.34615868e-03, -1.20126328e-03, -5.11507911e-04,\n",
              "         1.80452643e-03,  3.47875437e-04,  1.38473557e-03,\n",
              "        -1.40403071e-03, -1.75393827e-04,  1.22163247e-03,\n",
              "         5.20023059e-05,  7.51029118e-04, -7.18512980e-04,\n",
              "        -1.03973108e-03,  1.30544673e-03,  2.74613360e-03,\n",
              "        -1.44397502e-03, -7.58145587e-04,  1.10898749e-03,\n",
              "        -7.94039282e-04,  6.21773477e-04,  1.02543947e-03,\n",
              "        -1.03355094e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=\"colombia\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdYHSCC5FgM8",
        "outputId": "4affb766-7282-487d-a361-ade78aeb4070"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('colombiano', 0.8029711246490479),\n",
              " ('Colombia', 0.7584191560745239),\n",
              " ('hombre', 0.35941049456596375),\n",
              " ('octubre', 0.2678608298301697),\n",
              " ('nombre', 0.26743781566619873),\n",
              " ('quien', 0.2381267547607422),\n",
              " ('influencia', 0.2329128533601761),\n",
              " ('Según', 0.23193298280239105),\n",
              " ('como', 0.22788119316101074),\n",
              " ('con', 0.22718681395053864)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec"
      ],
      "metadata": {
        "id": "cRUhBLvgGsXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_corpus = [\n",
        "    TaggedDocument(doc, [i])\n",
        "    for i, doc in enumerate(token_corpus)\n",
        "]"
      ],
      "metadata": {
        "id": "ZJA6PoYfGtsu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6iSGX_tHNDA",
        "outputId": "e6b7abf8-543f-4d57-b457-fdb45f48c823"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['De', 'Wikipedia', ',', 'la', 'enciclopedia', 'libre', 'Para', 'otros', 'usos', 'de', 'este', 'término', ',', 'véase', 'Gabriel', 'García', 'Márquez', '(', 'desambiguación', ')', '.'], tags=[0]),\n",
              " TaggedDocument(words=['Gabriel', 'García', 'Márquez', 'Información', 'personalNombre', 'de', 'nacimiento', 'Gabriel', 'José', 'de', 'la', 'Concordia', 'García', 'MárquezApodo', 'Gabo', 'y', 'Gabito', 'Nacimiento', '6', 'de', 'marzo', 'de', '1927Aracataca', ',', 'ColombiaFallecimiento', '17', 'de', 'abril', 'de', '2014', '(', '87', 'años', ')', 'Ciudad', 'de', 'México', ',', 'MéxicoCausa', 'de', 'muerte', 'Linfoma', 'y', 'neumonía', 'Nacionalidad', 'ColombianaReligión', 'Ninguna', '[', '1', ']', '\\u200bLengua', 'materna', 'españolFamiliaPadres', 'Gabriel', 'Eligio', 'García', 'y', 'Luisa', 'Santiaga', 'MárquezCónyuge', 'Mercedes', 'Barcha', 'PardoHijos', 'Rodrigo', 'y', 'Gonzalo', 'García', ',', 'Indira', 'CatoEducaciónEducado', 'en', 'Universidad', 'Nacional', 'de', 'ColombiaInformación', 'profesionalOcupación', 'Escritor', ',', 'periodista', ',', 'editor', 'y', 'guionistaAños', 'activo', '1947-2010Movimientos', 'boom', 'latinoamericano', ',', 'realismo', 'mágicoSeudónimo', 'Gabito', ',', 'GaboLengua', 'literaria', 'españolGéneros', 'novela', ',', 'cuento', ',', 'crónica', ',', 'reportajeObras', 'notables', 'Cien', 'años', 'de', 'soledadCrónica', 'de', 'una', 'muerte', 'anunciadaEl', 'coronel', 'no', 'tiene', 'quien', 'le', 'escribaRelato', 'de', 'un', 'náufragoEl', 'amor', 'en', 'los', 'tiempos', 'del', 'cóleraDistinciones', 'Galardonado', 'con', 'el', 'Premio', 'Nobel', 'de', 'Literatura', '(', '1982', ')', 'Firma', '[', 'editar', 'datos', 'en', 'Wikidata', ']', 'Escucha', 'este', 'artículo', '(', 'info', ')', 'Esta', 'narración', 'de', 'audio', 'fue', 'creada', 'a', 'partir', 'de', 'una', 'versión', 'específica', 'de', 'este', 'artículo', '(', 'concretamente', 'del', '2', 'de', 'agosto', 'de', '2020', ')', 'y', 'no', 'refleja', 'las', 'posibles', 'ediciones', 'subsiguientes.Más', 'artículos', 'grabados¿Problemas', 'al', 'reproducir', 'este', 'archivo', '?'], tags=[1]),\n",
              " TaggedDocument(words=['Gabriel', 'José', 'de', 'la', 'Concordia', 'García', 'Márquez', '(', 'Aracataca', ',', 'Magdalena', ',', 'Colombia', ',', '6', 'de', 'marzo', 'de', '1927-Ciudad', 'de', 'México', ',', '17', 'de', 'abril', 'de', '2014', ')', '[', 'nota', '1', ']', '\\u200b', '[', '2', ']', '\\u200b', '(', 'escuchar', ')', 'fue', 'un', 'escritor', 'y', 'periodista', 'colombiano', '.'], tags=[2]),\n",
              " TaggedDocument(words=['Reconocido', 'principalmente', 'por', 'sus', 'novelas', 'y', 'cuentos', ',', 'también', 'escribió', 'narrativa', 'de', 'no', 'ficción', ',', 'discursos', ',', 'reportajes', ',', 'críticas', 'cinematográficas', 'y', 'memorias', '.'], tags=[3]),\n",
              " TaggedDocument(words=['Estudió', 'derecho', 'y', 'periodismo', 'en', 'la', 'Universidad', 'Nacional', 'de', 'Colombia', 'e', 'inicio', 'sus', 'primeras', 'colaboraciones', 'periodísticas', 'en', 'el', 'diario', 'El', 'Espectador', '.'], tags=[4]),\n",
              " TaggedDocument(words=['Fue', 'conocido', 'como', 'Gabo', ',', 'y', 'familiarmente', 'y', 'por', 'sus', 'amigos', 'como', 'Gabito', '.'], tags=[5]),\n",
              " TaggedDocument(words=['[', '3', ']', '\\u200b', '[', '4', ']', '\\u200b', 'En', '1982', 'recibió', 'el', 'Premio', 'Nobel', 'de', 'Literatura', '[', '5', ']', '\\u200b', '«', 'por', 'sus', 'novelas', 'e', 'historias', 'cortas', ',', 'en', 'las', 'que', 'lo', 'fantástico', 'y', 'lo', 'real', 'se', 'combinan', 'en', 'un', 'mundo', 'ricamente', 'compuesto', 'de', 'imaginación', ',', 'lo', 'que', 'refleja', 'la', 'vida', 'y', 'los', 'conflictos', 'de', 'un', 'continente', '»', '.'], tags=[6]),\n",
              " TaggedDocument(words=['[', '6', ']', '\\u200b', '[', '7', ']', '\\u200b', 'Junto', 'a', 'Julio', 'Cortázar', ',', 'Mario', 'Vargas', 'Llosa', 'y', 'Carlos', 'Fuentes', ',', 'fue', 'uno', 'de', 'los', 'exponentes', 'centrales', 'del', 'boom', 'latinoamericano', '.'], tags=[7]),\n",
              " TaggedDocument(words=['También', 'está', 'considerado', 'uno', 'de', 'los', 'principales', 'autores', 'del', 'realismo', 'mágico', ',', 'y', 'su', 'obra', 'más', 'conocida', ',', 'la', 'novela', 'Cien', 'años', 'de', 'soledad', ',', 'es', 'considerada', 'una', 'de', 'las', 'más', 'representativas', 'de', 'esa', 'corriente', 'literaria', ',', 'e', 'incluso', 'se', 'considera', 'que', 'se', 'debe', 'al', 'éxito', 'de', 'la', 'novela', 'el', 'hecho', 'de', 'que', 'el', 'término', 'se', 'aplique', 'a', 'la', 'literatura', 'surgida', 'a', 'partir', 'de', '1960', 'en', 'América', 'Latina', '.'], tags=[8]),\n",
              " TaggedDocument(words=['[', '8', ']', '\\u200b', '[', '9', ']', '\\u200b', 'En', '2007', 'la', 'Real', 'Academia', 'Española', 'y', 'la', 'Asociación', 'de', 'Academias', 'de', 'la', 'Lengua', 'Española', 'publicaron', 'una', 'edición', 'popular', 'conmemorativa', 'de', 'esta', 'obra', ',', 'por', 'considerarla', 'parte', 'de', 'los', 'grandes', 'clásicos', 'hispánicos', 'de', 'todos', 'los', 'tiempos', '.'], tags=[9])]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(\n",
        "    documents=tagged_corpus,\n",
        "    vector_size=100,\n",
        "    epochs=100,\n",
        "    workers=-1,\n",
        "    window=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miQ-6MKIHS0y",
        "outputId": "5b7dbe5b-7526-4488-c554-a4364d6227e6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 0: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 1: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 2: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 3: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 4: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 5: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 5: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 6: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 6: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 7: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 7: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 8: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 8: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 9: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 9: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 10: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 10: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 11: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 11: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 12: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 12: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 13: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 13: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 14: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 14: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 15: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 15: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 16: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 16: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 17: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 17: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 18: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 18: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 19: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 19: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 20: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 20: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 21: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 21: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 22: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 22: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 23: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 23: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 24: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 24: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 25: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 25: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 26: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 26: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 27: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 27: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 28: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 28: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 29: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 29: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 30: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 30: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 31: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 31: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 32: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 32: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 33: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 33: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 34: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 34: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 35: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 35: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 36: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 36: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 37: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 37: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 38: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 38: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 39: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 39: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 40: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 40: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 41: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 41: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 42: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 42: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 43: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 43: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 44: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 44: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 45: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 45: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 46: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 46: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 47: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 47: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 48: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 48: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 49: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 49: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 50: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 50: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 51: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 51: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 52: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 52: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 53: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 53: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 54: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 54: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 55: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 55: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 56: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 56: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 57: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 57: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 58: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 58: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 59: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 59: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 60: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 60: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 61: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 61: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 62: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 62: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 63: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 63: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 64: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 64: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 65: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 65: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 66: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 66: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 67: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 67: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 68: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 68: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 69: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 69: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 70: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 70: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 71: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 71: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 72: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 72: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 73: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 73: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 74: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 74: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 75: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 75: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 76: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 76: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 77: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 77: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 78: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 78: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 79: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 79: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 80: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 80: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 81: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 81: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 82: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 82: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 83: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 83: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 84: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 84: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 85: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 85: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 86: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 86: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 87: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 87: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 88: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 88: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 89: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 89: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 90: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 90: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 91: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 91: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 92: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 92: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 93: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 93: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 94: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 94: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 95: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 95: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 96: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 96: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 97: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 97: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 98: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 98: supplied raw word count (0) did not equal expected count (15876)\n",
            "WARNING:gensim.models.word2vec:EPOCH 99: supplied example count (0) did not equal expected count (647)\n",
            "WARNING:gensim.models.word2vec:EPOCH 99: supplied raw word count (0) did not equal expected count (15876)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[[\"Gabriel\", \"Gabo\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DueqiFMHoCJ",
        "outputId": "60c9ce1e-25ad-4a0c-a523-7d6a3e3596f6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.6485280e-03,  7.3248292e-03,  1.2616563e-03, -3.4052359e-03,\n",
              "        -4.5065998e-04,  4.2262315e-04, -6.4092050e-03,  5.7451581e-03,\n",
              "         2.3714018e-03,  3.7779354e-03, -7.2550178e-03,  8.5262908e-03,\n",
              "         5.0825358e-04, -2.0392657e-04, -9.0716071e-03,  4.0487554e-03,\n",
              "         6.7634354e-03,  7.3550926e-03, -6.4175250e-03, -7.8560598e-03,\n",
              "        -5.5237138e-03, -6.0289743e-04, -8.3379801e-03, -8.2401158e-03,\n",
              "        -1.9175697e-03,  1.1392868e-03, -9.5065478e-03, -3.7329339e-03,\n",
              "         6.4478040e-04,  6.8099652e-03,  1.7349911e-03, -6.3238264e-04,\n",
              "        -7.4813948e-03, -6.7420946e-03, -6.9442869e-04,  7.4675824e-03,\n",
              "         5.4428698e-03, -1.4826906e-03,  1.1723089e-03, -9.6057765e-03,\n",
              "        -1.3844955e-03, -4.6262229e-03,  5.8093108e-03, -2.3380124e-03,\n",
              "        -4.7640656e-03, -9.4751148e-03, -1.2003147e-03, -7.1977698e-03,\n",
              "        -1.6852176e-03, -4.0698228e-03, -2.3741352e-03, -3.2483351e-03,\n",
              "        -8.1564728e-03, -1.2484109e-03,  1.6909433e-03, -4.0476443e-03,\n",
              "        -7.6414524e-03, -3.5866357e-03, -9.0471338e-03, -7.5842498e-04,\n",
              "         5.8830045e-03, -2.9613459e-03,  3.1617582e-03,  4.9957181e-03,\n",
              "         8.4684277e-03,  5.6214156e-03,  9.5085464e-03, -9.6466811e-03,\n",
              "        -7.9626748e-03, -6.7581558e-03, -7.4677086e-03, -7.9636183e-03,\n",
              "        -7.7881692e-03, -2.9426264e-03,  1.3961601e-03, -2.8747893e-03,\n",
              "        -8.8162515e-03,  4.9858619e-03,  9.0089085e-04,  4.5904014e-03,\n",
              "         7.1953381e-03,  7.6482939e-03, -8.0464722e-04,  3.6599601e-03,\n",
              "        -5.1235761e-03,  1.9106817e-03,  4.5382692e-03,  9.8866634e-03,\n",
              "        -3.1874895e-03,  2.8393341e-03, -5.7363496e-03, -2.2105658e-03,\n",
              "         8.1250956e-03, -3.9046574e-03, -1.1885798e-03, -9.2849741e-03,\n",
              "        -9.4767762e-03,  8.8827666e-03, -5.7029221e-03,  5.0527919e-03],\n",
              "       [ 6.9790934e-03, -2.0951152e-04, -7.9470100e-03,  8.8905953e-03,\n",
              "        -8.5516348e-03,  5.5598891e-03,  6.4678504e-03,  9.7577932e-04,\n",
              "        -8.6925616e-03,  6.1753215e-03, -7.8478707e-03, -5.0177681e-03,\n",
              "         9.6247876e-03, -8.2821418e-03, -7.6285531e-03, -4.9005579e-03,\n",
              "         3.4631919e-03,  1.9144202e-03, -5.5585168e-03, -3.2763958e-03,\n",
              "         8.5835531e-03,  9.7675994e-03,  9.9147148e-03,  1.0454941e-03,\n",
              "         4.0380000e-03,  1.3658536e-03,  1.6727329e-03,  4.8383819e-03,\n",
              "         2.2040391e-03,  3.0054449e-04, -3.1488347e-03, -6.5247416e-03,\n",
              "         7.9894923e-03, -5.9719621e-03,  2.7833520e-03, -9.2541694e-04,\n",
              "        -3.6488725e-03, -4.9413932e-03,  3.2202196e-03, -5.8576204e-03,\n",
              "        -7.4947942e-03, -2.6441026e-03,  4.6893787e-03,  6.0440982e-03,\n",
              "        -1.4566731e-03,  7.2986148e-03, -7.5932704e-03, -4.7327732e-03,\n",
              "        -7.8608748e-03, -6.0471091e-03,  7.3008193e-03, -9.2807058e-03,\n",
              "        -8.6519560e-03, -9.8145390e-03,  9.2028119e-03, -2.6650822e-03,\n",
              "         9.9734659e-04, -6.1275125e-03, -2.5342822e-03,  7.2566268e-05,\n",
              "        -2.5002421e-03, -7.3716044e-03, -6.1929417e-03,  2.5351786e-03,\n",
              "        -9.4943373e-03,  1.1462688e-03, -1.9883560e-03,  8.2782693e-03,\n",
              "        -3.9780259e-04,  6.2138676e-03, -7.0868339e-03, -7.5677098e-03,\n",
              "         5.5462597e-03,  9.3976018e-04, -5.0903237e-03, -2.6597893e-03,\n",
              "         8.7711522e-03, -9.1774324e-03, -3.6765123e-03,  1.0024810e-03,\n",
              "        -2.1608472e-04,  9.5136138e-03, -1.9383347e-03, -7.0953299e-03,\n",
              "        -7.6787388e-03, -9.9005364e-03, -7.8236489e-03, -6.0328604e-03,\n",
              "        -5.9469976e-03, -1.4051843e-03, -5.4117083e-04, -4.7152913e-03,\n",
              "         2.1409167e-03,  3.8658725e-03,  9.0301884e-03, -4.6547530e-03,\n",
              "         5.1285233e-03,  7.2539425e-03, -3.7568689e-03, -7.4346815e-03]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = model.infer_vector([\"esta\", \"es\", \"la\", \"casa\", \"de\", \"Gabriel\"])\n",
        "vect.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV4GUToIH0wN",
        "outputId": "a7917e57-bccf-4bec-ecae-d4b2f7438ad3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos Pre-Entrenados"
      ],
      "metadata": {
        "id": "sGr5Jz24Icj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "info = api.info()"
      ],
      "metadata": {
        "id": "GOMRUrW_Iovm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"file.json\", \"w\") as f:\n",
        "    json.dump(info, f)"
      ],
      "metadata": {
        "id": "gMugx8rjIrzd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "apt install jq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF0x-n4fI3yj",
        "outputId": "271fa8e2-9149-43cb-c0c9-c28619d6c8a6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libjq1 libonig5\n",
            "The following NEW packages will be installed:\n",
            "  jq libjq1 libonig5\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 357 kB of archives.\n",
            "After this operation, 1,087 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libonig5 amd64 6.9.7.1-2build1 [172 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjq1 amd64 1.6-2.1ubuntu3 [133 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 jq amd64 1.6-2.1ubuntu3 [52.5 kB]\n",
            "Fetched 357 kB in 1s (457 kB/s)\n",
            "Selecting previously unselected package libonig5:amd64.\n",
            "(Reading database ... 120895 files and directories currently installed.)\n",
            "Preparing to unpack .../libonig5_6.9.7.1-2build1_amd64.deb ...\n",
            "Unpacking libonig5:amd64 (6.9.7.1-2build1) ...\n",
            "Selecting previously unselected package libjq1:amd64.\n",
            "Preparing to unpack .../libjq1_1.6-2.1ubuntu3_amd64.deb ...\n",
            "Unpacking libjq1:amd64 (1.6-2.1ubuntu3) ...\n",
            "Selecting previously unselected package jq.\n",
            "Preparing to unpack .../jq_1.6-2.1ubuntu3_amd64.deb ...\n",
            "Unpacking jq (1.6-2.1ubuntu3) ...\n",
            "Setting up libonig5:amd64 (6.9.7.1-2build1) ...\n",
            "Setting up libjq1:amd64 (1.6-2.1ubuntu3) ...\n",
            "Setting up jq (1.6-2.1ubuntu3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cat file.json | jq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWlcNKSKI9hL",
        "outputId": "0a70c3ee-86a4-4afe-8341-b8a6bf5a4c86"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;39m{\n",
            "  \u001b[0m\u001b[34;1m\"corpora\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "    \u001b[0m\u001b[34;1m\"semeval-2016-2017-task3-subtaskBC\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m-1\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dict\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m6344358\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskB-eng/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"All files released for the task are free for general research use\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"fields\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"2016-train\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "          \u001b[0;32m\"...\"\u001b[0m\u001b[1;39m\n",
            "        \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"2016-dev\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "          \u001b[0;32m\"...\"\u001b[0m\u001b[1;39m\n",
            "        \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"2017-test\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "          \u001b[0;32m\"...\"\u001b[0m\u001b[1;39m\n",
            "        \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"2016-test\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "          \u001b[0;32m\"...\"\u001b[0m\u001b[1;39m\n",
            "        \u001b[1;39m]\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"SemEval 2016 / 2017 Task 3 Subtask B and C datasets contain train+development (317 original questions, 3,169 related questions, and 31,690 comments), and test datasets in English. The description of the tasks and the collected data is given in sections 3 and 4.1 of the task paper http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf linked in section “Papers” of https://github.com/RaRe-Technologies/gensim-data/issues/18.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"701ea67acd82e75f95e1d8e62fb0ad29\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"semeval-2016-2017-task3-subtaskBC.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://alt.qcri.org/semeval2017/task3/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"http://alt.qcri.org/semeval2017/task3/data/uploads/semeval2017-task3.pdf\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/issues/18\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://github.com/Witiko/semeval-2016_2017-task3-subtaskB-english\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"semeval-2016-2017-task3-subtaskA-unannotated\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m189941\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dict\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m234373151\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/semeval-2016-2017-task3-subtaskA-unannotated-eng/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"These datasets are free for general research use.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"fields\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"THREAD_SEQUENCE\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"RelQuestion\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "          \u001b[0m\u001b[34;1m\"RELQ_CATEGORY\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"question category, according to the Qatar Living taxonomy\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"RELQ_DATE\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"date of posting\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"RELQ_ID\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"question indentifier\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"RELQ_USERID\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"identifier of the user asking the question\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"RELQ_USERNAME\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"name of the user asking the question\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"RelQBody\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"body of question\"\u001b[0m\u001b[1;39m,\n",
            "          \u001b[0m\u001b[34;1m\"RelQSubject\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"subject of question\"\u001b[0m\u001b[1;39m\n",
            "        \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"RelComments\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "          \u001b[1;39m{\n",
            "            \u001b[0m\u001b[34;1m\"RelCText\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"text of answer\"\u001b[0m\u001b[1;39m,\n",
            "            \u001b[0m\u001b[34;1m\"RELC_USERID\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"identifier of the user posting the comment\"\u001b[0m\u001b[1;39m,\n",
            "            \u001b[0m\u001b[34;1m\"RELC_ID\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"comment identifier\"\u001b[0m\u001b[1;39m,\n",
            "            \u001b[0m\u001b[34;1m\"RELC_USERNAME\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"name of the user posting the comment\"\u001b[0m\u001b[1;39m,\n",
            "            \u001b[0m\u001b[34;1m\"RELC_DATE\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"date of posting\"\u001b[0m\u001b[1;39m\n",
            "          \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
            "        \u001b[1;39m]\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"SemEval 2016 / 2017 Task 3 Subtask A unannotated dataset contains 189,941 questions and 1,894,456 comments in English collected from the Community Question Answering (CQA) web forum of Qatar Living. These can be used as a corpus for language modelling.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"2de0e2f2c4f91c66ae4fcf58d50ba816\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"semeval-2016-2017-task3-subtaskA-unannotated.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://alt.qcri.org/semeval2016/task3/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"http://alt.qcri.org/semeval2016/task3/data/uploads/semeval2016-task3-report.pdf\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/issues/18\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://github.com/Witiko/semeval-2016_2017-task3-subtaskA-unannotated-english\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"patent-2017\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m353197\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dict\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3087262469\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/patent-2017/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"not found\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Patent Grant Full Text. Contains the full text including tables, sequence data and 'in-line' mathematical expressions of each patent grant issued in 2017.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-0\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"818501f0b9af62d3b88294d86d509f8f\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-1\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"66c05635c1d3c7a19b4a335829d09ffa\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"patent-2017.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://patents.reedtech.com/pgrbft.php\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"quora-duplicate-questions\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m404290\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dict\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m21684784\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/quora-duplicate-questions/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"probably https://www.quora.com/about/tos\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"fields\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"question1\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"the full text of each question\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"question2\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"the full text of each question\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"qid1\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unique ids of each question\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"qid2\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unique ids of each question\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"the id of a training set question pair\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"is_duplicate\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Over 400,000 lines of potential question duplicate pairs. Each line contains IDs for each question in the pair, the full text for each question, and a binary value that indicates whether the line contains a duplicate pair or not.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d7cfa7fbc6e2ec71ab74c495586c6365\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"quora-duplicate-questions.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"wiki-english-20171001\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m4924894\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dict\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m6516051717\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/wiki-english-20171001/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://dumps.wikimedia.org/legal.html\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"fields\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"section_texts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"list of body of sections\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"section_titles\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"list of titles of sections\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Title of wiki article\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Extracted Wikipedia dump from October 2017. Produced by `python -m gensim.scripts.segment_wiki -f enwiki-20171001-pages-articles.xml.bz2 -o wiki-en.gz`\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-0\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"a7d7d7fd41ea7e2d7fa32ec1bb640d71\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-1\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"b2683e3356ffbca3b6c2dca6e9801f9f\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-2\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"c5cde2a9ae77b3c4ebce804f6df542c2\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-3\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"00b71144ed5e3aeeb885de84f7452b81\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"wiki-english-20171001.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://dumps.wikimedia.org/enwiki/20171001/\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m4\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"text8\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1701\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"list of str (tokens)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m33182058\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"not found\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"68799af40b6bda07dfa47a32612e5364\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"text8.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://mattmahoney.net/dc/textdata.html\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"fake-news\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m12999\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dict\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m20102776\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/fake-news/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://creativecommons.org/publicdomain/zero/1.0/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"fields\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"crawled\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"date the story was archived\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"ord_in_thread\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"published\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"date published\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"participants_count\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"number of participants\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"shares\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"number of Facebook shares\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"replies_count\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"number of replies\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"main_img_url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"image from story\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"spam_score\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"data from webhose.io\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unique identifier\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"language\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"data from webhose.io\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"title of story\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"country\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"data from webhose.io\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"domain_rank\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"data from webhose.io\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"author\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"author of story\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"comments\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"number of Facebook comments\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"site_url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"site URL from BS detector\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"text of story\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"thread_title\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"type of website (label from BS detector)\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"likes\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"number of Facebook likes\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"News dataset, contains text and metadata from 244 websites and represents 12,999 posts in total from a specific window of 30 days. The data was pulled using the webhose.io API, and because it's coming from their crawler, not all websites identified by their BS Detector are present in this dataset. Data sources that were missing a label were simply assigned a label of 'bs'. There are (ostensibly) no genuine, reliable, or trustworthy news sources represented in this dataset (so far), so don't trust anything you read.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"5e64e942df13219465927f92dcefd5fe\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"fake-news.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://www.kaggle.com/mrisdal/fake-news\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"20-newsgroups\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m18846\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"record_format\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dict\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m14483581\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/20-newsgroups/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"not found\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"fields\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"topic\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"name of topic (20 variant of possible values)\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"set\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"marker of original split (possible values 'train' and 'test')\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"data\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"original id inferred from folder name\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"The notorious collection of approximately 20,000 newsgroup posts, partitioned (nearly) evenly across 20 different newsgroups.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"c92fd4f6640a86d5ba89eaad818a9891\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"20-newsgroups.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://qwone.com/~jason/20Newsgroups/\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"__testing_matrix-synopsis\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"1767ac93a089b43899d54944b07d9dc5\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"__testing_matrix-synopsis.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"__testing_multipart-matrix-synopsis\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"[THIS IS ONLY FOR TESTING] Synopsis of the movie matrix.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-0\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"c8b0c7d8cf562b1b632c262a173ac338\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-1\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"5ff7fc6818e9a5d9bc1cf12c35ed8b96\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum-2\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"966db9d274d125beaac7987202076cba\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"__testing_multipart-matrix-synopsis.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://www.imdb.com/title/tt0133093/plotsummary?ref_=ttpl_pl_syn#synopsis\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
            "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"models\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "    \u001b[0m\u001b[34;1m\"fasttext-wiki-news-subwords-300\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m999999\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1005007116\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/fasttext-wiki-news-subwords-300/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://creativecommons.org/licenses/by-sa/3.0/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m300\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://fasttext.cc/docs/en/english-vectors.html\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://arxiv.org/abs/1712.09405\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://arxiv.org/abs/1607.01759\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"de2bb3a20c46ce65c9c131e1ad9a77af\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"fasttext-wiki-news-subwords-300.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"conceptnet-numberbatch-17-06-300\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1917247\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1225497562\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ConceptNet, word2vec, GloVe, and OpenSubtitles 2016\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/conceptnet-numberbatch-17-06-300/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/commonsense/conceptnet-numberbatch/blob/master/LICENSE.txt\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m300\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ConceptNet Numberbatch consists of state-of-the-art semantic vectors (also known as word embeddings) that can be used directly as a representation of word meanings or as a starting point for further machine learning. ConceptNet Numberbatch is part of the ConceptNet open data project. ConceptNet provides lots of ways to compute with word meanings, one of which is word embeddings. ConceptNet Numberbatch is a snapshot of just the word embeddings. It is built using an ensemble that combines data from ConceptNet, word2vec, GloVe, and OpenSubtitles 2016, using a variation on retrofitting.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://github.com/commonsense/conceptnet-numberbatch\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"http://conceptnet.io/\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"fd642d457adcd0ea94da0cd21b150847\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"conceptnet-numberbatch-17-06-300.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"word2vec-ruscorpora-300\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m184973\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m208427381\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Russian National Corpus (about 250M words)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-ruscorpora-300/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://creativecommons.org/licenses/by/4.0/deed.en\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m300\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0m\u001b[34;1m\"window_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m10\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Word2vec Continuous Skipgram vectors trained on full Russian National Corpus (about 250M words). The model contains 185K words.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"The corpus was lemmatized and tagged with Universal PoS\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://www.academia.edu/24306935/WebVectors_a_Toolkit_for_Building_Web_Interfaces_for_Vector_Semantic_Models\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"http://rusvectores.org/en/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/issues/3\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"9bdebdc8ae6d17d20839dd9b5af10bc4\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"word2vec-ruscorpora-300.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"word2vec-google-news-300\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3000000\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1743563840\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Google News (about 100 billion words)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"not found\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m300\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' (https://code.google.com/archive/p/word2vec/).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://code.google.com/archive/p/word2vec/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://arxiv.org/abs/1301.3781\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://arxiv.org/abs/1310.4546\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"a5e5354d40acb95f9ec66d5977d140ef\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"word2vec-google-news-300.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-wiki-gigaword-50\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m400000\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m69182535\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m50\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"c289bc5d7f2f02c6dc9f2f9b67641813\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-wiki-gigaword-50.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-wiki-gigaword-100\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m400000\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m134300434\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-100/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m100\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on Wikipedia 2014 + Gigaword 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-100.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"40ec481866001177b8cd4cb0df92924f\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-wiki-gigaword-100.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-wiki-gigaword-200\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m400000\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m264336934\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-200/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m200\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-200.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"59652db361b7a87ee73834a6c391dfc1\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-wiki-gigaword-200.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-wiki-gigaword-300\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m400000\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m394362229\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-300/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m300\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-300.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"29e9329ac2241937d55b852e8284e89b\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-wiki-gigaword-300.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-twitter-25\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1193514\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m109885004\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-25/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m25\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-25.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"50db0211d7e7a2dcd362c6b774762793\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-twitter-25.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-twitter-50\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1193514\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m209216938\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-50/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m50\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-50.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"c168f18641f8c8a00fe30984c4799b2b\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-twitter-50.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-twitter-100\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1193514\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m405932991\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-100/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m100\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on  2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-100.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"b04f7bed38756d64cf55b58ce7e97b15\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-twitter-100.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"glove-twitter-200\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1193514\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m795373100\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-200/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m200\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-200.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "        \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"e52e8392d1860b95d5308a525817d8f9\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-twitter-200.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0m\u001b[34;1m\"__testing_word2vec-matrix-synopsis\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "      \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"[THIS IS ONLY FOR TESTING] Word vecrors of the movie matrix.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "        \u001b[0m\u001b[34;1m\"dimensions\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m50\u001b[0m\u001b[1;39m\n",
            "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v using a preprocessed corpus. Converted to w2v format with `python3.5 -m gensim.models.word2vec -train <input_filename> -iter 50 -output <output_filename>`.\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[]\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"534dcb8b56a360977a269b7bfc62d124\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"__testing_word2vec-matrix-synopsis.gz\"\u001b[0m\u001b[1;39m,\n",
            "      \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
            "  \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
            "\u001b[1;39m}\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_meta = info[\"models\"][\"glove-twitter-25\"]"
      ],
      "metadata": {
        "id": "VwRdapg8KVcw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"file.json\", \"w\") as f:\n",
        "    json.dump(model_meta, f)"
      ],
      "metadata": {
        "id": "q9WxVF-NKbd7"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cat \"file.json\" | jq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8GMjeK3KgyS",
        "outputId": "13e8fcee-1b01-49da-c3cf-b69e04e5e944"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;39m{\n",
            "  \u001b[0m\u001b[34;1m\"num_records\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1193514\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"file_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m109885004\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"base_dataset\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"reader_code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-25/__init__.py\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"license\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"http://opendatacommons.org/licenses/pddl/\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"parameters\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
            "    \u001b[0m\u001b[34;1m\"dimension\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m25\u001b[0m\u001b[1;39m\n",
            "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"description\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"preprocessing\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-25.txt`.\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"read_more\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
            "    \u001b[0;32m\"https://nlp.stanford.edu/projects/glove/\"\u001b[0m\u001b[1;39m,\n",
            "    \u001b[0;32m\"https://nlp.stanford.edu/pubs/glove.pdf\"\u001b[0m\u001b[1;39m\n",
            "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"checksum\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"50db0211d7e7a2dcd362c6b774762793\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"file_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"glove-twitter-25.gz\"\u001b[0m\u001b[1;39m,\n",
            "  \u001b[0m\u001b[34;1m\"parts\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\n",
            "\u001b[1;39m}\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"glove-twitter-25\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdaknoHiKyud",
        "outputId": "cd950cb8-da3a-4f5c-bf46-d2e54d154581"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOcOLaPfLDwq",
        "outputId": "96d57186-5e86-4a0f-a71f-52603e18f5ba"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.keyedvectors.KeyedVectors"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[\"hello\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7DXcdM1LNhV",
        "outputId": "e6e21d32-3724-4be8-8cb9-faa43fcd8549"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.77069  ,  0.12827  ,  0.33137  ,  0.0050893, -0.47605  ,\n",
              "       -0.50116  ,  1.858    ,  1.0624   , -0.56511  ,  0.13328  ,\n",
              "       -0.41918  , -0.14195  , -2.8555   , -0.57131  , -0.13418  ,\n",
              "       -0.44922  ,  0.48591  , -0.6479   , -0.84238  ,  0.61669  ,\n",
              "       -0.19824  , -0.57967  , -0.65885  ,  0.43928  , -0.50473  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[[\"this\", \"is\", \"an\", \"example\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVi5UVCJLQkt",
        "outputId": "4691a03a-14e4-454d-e442-29e34115504c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.17895 ,  0.38406 ,  0.073035, -0.32363 , -0.092441, -0.40767 ,\n",
              "         2.1     , -0.11363 , -0.58784 , -0.17034 , -0.6433  ,  0.72388 ,\n",
              "        -5.7839  , -0.10406 ,  0.52152 , -0.11314 ,  0.59554 , -0.47587 ,\n",
              "        -0.4551  ,  0.084431, -0.4582  , -0.16727 ,  0.54594 ,  0.035478,\n",
              "        -0.16073 ],\n",
              "       [-0.12532 , -0.20207 , -0.12672 , -0.57474 , -0.30313 , -0.029884,\n",
              "         1.1792  , -0.1491  , -0.71315 , -0.12112 ,  0.40652 ,  1.4784  ,\n",
              "        -5.995   , -0.21617 ,  0.47806 ,  0.43448 ,  0.13489 ,  0.88961 ,\n",
              "        -0.56926 ,  0.33094 ,  0.13661 ,  0.65844 , -0.41766 ,  0.25164 ,\n",
              "        -0.055809],\n",
              "       [ 0.54244 ,  0.45753 , -0.45787 ,  0.066361,  0.58916 ,  0.57979 ,\n",
              "         0.49853 ,  0.44921 ,  0.3961  ,  0.83226 ,  0.24802 ,  0.82883 ,\n",
              "        -4.5964  ,  0.31983 , -0.39849 , -0.39169 ,  1.0018  ,  0.33518 ,\n",
              "        -1.1096  , -0.80148 , -0.50184 ,  0.85388 , -0.86857 , -0.18002 ,\n",
              "        -0.23887 ],\n",
              "       [ 0.15773 , -0.17057 , -0.54851 ,  0.17185 ,  0.58238 , -0.34551 ,\n",
              "         1.1905  , -0.73965 ,  0.17331 , -0.43943 , -0.50311 ,  0.70757 ,\n",
              "        -3.2831  ,  0.30243 ,  0.22886 ,  0.16294 ,  0.118   ,  0.26068 ,\n",
              "         0.44564 , -0.075968,  0.19754 ,  0.21364 , -0.90991 , -0.16503 ,\n",
              "        -0.96921 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model[\"eausuaheo\"]\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edBNhtHJLT9I",
        "outputId": "c76e8ca4-a446-4f9d-efaa-9d49753baa98"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Key 'eausuaheo' not present\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`king - man + woman = queen`"
      ],
      "metadata": {
        "id": "aVQHGIUzLwNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=[\"car\", \"fly\"], negative=[\"wheels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iozeO6sGLmDP",
        "outputId": "f6146b9b-e34d-468a-f77b-ee8a9c495331"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ca', 0.911242663860321),\n",
              " ('stop', 0.8819992542266846),\n",
              " ('on', 0.8809431791305542),\n",
              " ('go', 0.8696092963218689),\n",
              " ('leave', 0.8662277460098267),\n",
              " ('call', 0.8622737526893616),\n",
              " ('take', 0.8444519639015198),\n",
              " ('come', 0.843082845211029),\n",
              " ('stay', 0.8398045897483826),\n",
              " ('stand', 0.8390660881996155)]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Spark"
      ],
      "metadata": {
        "id": "blka4viwDHRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "apt install openjdk-8-jdk-headless -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztGJeA7ZtZqS",
        "outputId": "7ece85c0-8e27-4020-8585-69769e798b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u382-ga-1~22.04.1 [30.8 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u382-ga-1~22.04.1 [8,851 kB]\n",
            "Fetched 39.7 MB in 1s (37.3 MB/s)\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 120895 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "c3MxmdbOuknn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmEPjCAtuoEd",
        "outputId": "a9460b8a-5081-4d31-9807-b9e0068d6db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=2170c60f3f0f97a5ac48650ac3f8259cee60ec805cffe7f0cc2c78e17a562e0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import Row, StringType, StructType, StructField\n",
        "from pyspark.ml.feature import Word2Vec, Tokenizer\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "XMb5y-oeuqX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = (\n",
        "    SparkConf()\n",
        "    .setAppName(\"bow\")\n",
        "    .setMaster(\"local[4]\")\n",
        ")"
      ],
      "metadata": {
        "id": "jq7iTmIuusv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "metadata": {
        "id": "nx3aDi08uzYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = (\n",
        "    sc.parallelize(corpus)\n",
        "    .map(lambda text: Row(text=text))\n",
        ")"
      ],
      "metadata": {
        "id": "_jwnZJRQu1bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(rdd)"
      ],
      "metadata": {
        "id": "7tZ1qtqNvdei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojIEJY3Uvx7G",
        "outputId": "47bf98e5-8edb-486d-cdf5-df53b6cdfa4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChWNSKTCvzpg",
        "outputId": "9e50b9c7-07d0-40b4-95c8-dae6ca53ce8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|\\n\\n\\n\\n\\nDe Wiki...|\n",
            "|Gabriel García Má...|\n",
            "|Gabriel José de l...|\n",
            "|Reconocido princi...|\n",
            "|Estudió derecho y...|\n",
            "|Fue conocido como...|\n",
            "|[3]​[4]​ En 1982 ...|\n",
            "|[6]​[7]​ \\nJunto ...|\n",
            "|También está cons...|\n",
            "|[8]​[9]​ En 2007 ...|\n",
            "+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
        "vectorizer = Word2Vec(\n",
        "    vectorSize=30,\n",
        "    maxIter=100,\n",
        "    windowSize=5,\n",
        "    inputCol=\"tokens\",\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "pipe = Pipeline(stages=[\n",
        "    tokenizer, vectorizer\n",
        "])"
      ],
      "metadata": {
        "id": "5hMFwoWSv2vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipe.fit(dataset=df)"
      ],
      "metadata": {
        "id": "aNcTo0qcwR-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transform(dataset=df)"
      ],
      "metadata": {
        "id": "cNew0wVSwc-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK2SK16Awn0s",
        "outputId": "4be26054-ae5d-4ba6-a4d8-fa6d1d82b070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                text|              tokens|            features|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|\\n\\n\\n\\n\\nDe Wiki...|[, , , , , de, wi...|[0.15242741210386...|\n",
            "|Gabriel García Má...|[gabriel, garcía,...|[0.09619051708789...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    result\n",
        "    .select(result.features)\n",
        "    .toPandas()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xCT1CltdwpSs",
        "outputId": "853cc9ee-294c-403d-bcf7-2bc4bbb4c687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              features\n",
              "0    [0.15242741210386157, 0.10983077886824806, -0....\n",
              "1    [0.09619051708789643, -0.00018111060925586495,...\n",
              "2    [0.15935551735662645, -0.08035142317173942, -0...\n",
              "3    [0.059145085513591766, -0.1288564793373409, -0...\n",
              "4    [0.08637617049472672, -0.18017011650261425, 0....\n",
              "..                                                 ...\n",
              "642  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "643  [0.06535556813081106, -0.07777485474944115, -0...\n",
              "644  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "645  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "646  [0.054005388827530316, 0.1696076999542011, -0....\n",
              "\n",
              "[647 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a2fc1ed-a981-4f3d-8338-7e21ec18bcea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.15242741210386157, 0.10983077886824806, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.09619051708789643, -0.00018111060925586495,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.15935551735662645, -0.08035142317173942, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.059145085513591766, -0.1288564793373409, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.08637617049472672, -0.18017011650261425, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>[0.06535556813081106, -0.07777485474944115, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>645</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>[0.054005388827530316, 0.1696076999542011, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>647 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a2fc1ed-a981-4f3d-8338-7e21ec18bcea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a2fc1ed-a981-4f3d-8338-7e21ec18bcea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a2fc1ed-a981-4f3d-8338-7e21ec18bcea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-639eabbb-0425-4413-a553-7d396c0e789b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-639eabbb-0425-4413-a553-7d396c0e789b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-639eabbb-0425-4413-a553-7d396c0e789b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ynK7AK0pwx3-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}